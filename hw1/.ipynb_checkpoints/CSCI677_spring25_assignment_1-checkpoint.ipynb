{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u93YJyjNB9WK"
   },
   "source": [
    "# Introduction\n",
    "\n",
    "In this assignment you will practice calibrating a camera, computing homography between images and stitching panoramas. The goals of this assignment are as follows:\n",
    "\n",
    "\n",
    "\n",
    "*   Understand the intrinsic parameters of a prospective camera.\n",
    "*   Understand feature detection and feature matching process.\n",
    "*   Find the intrinsic and extrinsic parameters of a camera using ChArUco patterns.\n",
    "*   Compute homography between two images.\n",
    "*   Use homography to stitch panoramas.\n",
    "\n",
    "Please fill in all the **TODO** blocks (including codes and texts). Most of the assignment can be done by calling functions in OpenCV. Once you are ready to submit:\n",
    "\n",
    "* Export the notebook `CSCI677_spring25_assignment_1.ipynb` as a PDF `[Your USC ID]_CSCI677_spring25_assignment_1.pdf` and submit the PDF\n",
    "\n",
    "Please make sure that the notebook have been run before exporting PDF, and your code and all cell outputs are visible in your submitted PDF. Regrading request will not be accepted if your code/output is not visible in the original submission. Thank you!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dr_Wv6Hi3Y_K"
   },
   "source": [
    "# Calibration (35 pts)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Sp9dU9BxtSsd"
   },
   "source": [
    "## Data Collection (5 points)\n",
    "\n",
    "To determine the intrinsic parameters of a camera, you will need to capture sample images of an [ChArUco board](https://docs.opencv.org/4.x/db/da9/tutorial_aruco_board_detection.html). These images are obtained by photographing printed ChArUco patterns displayed on a flat surface or screen.\n",
    "\n",
    "### Steps:\n",
    "1. Use the provided sample code to generate your own ChArUco pattern. Feel free to adjust the function parameters.\n",
    "2. Print the generated pattern or display it on a flat screen.\n",
    "3. Capture at least **10 photos** of the ChArUco board from **different angles** to ensure accuracy in calibration.\n",
    "4. Make sure that **each photo covers the entire ChArUco board** for proper detection.\n",
    "\n",
    "These images will be used later for camera calibration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-10T04:05:03.298159Z",
     "start_time": "2025-02-10T04:05:03.129794Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChArUco board saved at: ./charuco_boards/charuco_4_7x5_1.0_0.8.tiff\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "from cv2 import aruco\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "def generate_charuco_board(\n",
    "    save_dir: str, \n",
    "    squares_x: int = 7, \n",
    "    squares_y: int = 5, \n",
    "    square_length: float = 1.0, \n",
    "    marker_length: float = 0.8, \n",
    "    aruco_dict_type: int = aruco.DICT_5X5_50, \n",
    "    image_size: tuple = (2000, 2000),\n",
    "    plot_results: bool = False\n",
    ") -> tuple:\n",
    "    \"\"\"\n",
    "    Generates and saves a ChArUco board image.\n",
    "    \n",
    "    Args:\n",
    "        save_dir (str): Directory to save the generated ChArUco board image.\n",
    "        squares_x (int): Number of squares along the horizontal direction.\n",
    "        squares_y (int): Number of squares along the vertical direction.\n",
    "        square_length (float): Side length of each square (in arbitrary units).\n",
    "        marker_length (float): Side length of each marker (in arbitrary units).\n",
    "        aruco_dict_type (int): Type of the ArUco dictionary to use.\n",
    "        image_size (tuple): Size of the output image (width, height).\n",
    "        plot_results (bool): Whether to display the generated board.\n",
    "    \n",
    "    Returns:\n",
    "        tuple: The ArUco dictionary and ChArUco board object.\n",
    "    \"\"\"\n",
    "    # Ensure the save directory exists\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    \n",
    "    # Create the ArUco dictionary\n",
    "    aruco_dict = aruco.Dictionary_get(aruco_dict_type)\n",
    "    \n",
    "    # Create the ChArUco board\n",
    "    board = aruco.CharucoBoard_create(\n",
    "        squares_x, squares_y, square_length, marker_length, aruco_dict\n",
    "    )\n",
    "    \n",
    "    # Generate the board image\n",
    "    board_image = board.draw(image_size)\n",
    "    \n",
    "    # Save the image with a unique name\n",
    "    filename = f\"charuco_{aruco_dict_type}_{squares_x}x{squares_y}_{square_length}_{marker_length}.tiff\"\n",
    "    filepath = os.path.join(save_dir, filename)\n",
    "    cv2.imwrite(filepath, board_image)\n",
    "    print(f\"ChArUco board saved at: {filepath}\")\n",
    "    \n",
    "    # Optionally plot the board\n",
    "    if plot_results:\n",
    "        plt.figure(figsize=(8, 8))\n",
    "        plt.imshow(board_image, cmap='gray', interpolation=\"nearest\")\n",
    "        plt.axis(\"off\")\n",
    "        plt.show()\n",
    "    \n",
    "    return aruco_dict, board\n",
    "\n",
    "# Example usage\n",
    "save_directory = \"./charuco_boards/\"\n",
    "aruco_dict, charuco_board = generate_charuco_board(\n",
    "    save_dir=save_directory, \n",
    "    plot_results=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PwdMZskzXL_T"
   },
   "source": [
    "## Calibration (15 pts)\n",
    "To calibrate the camera, you will need to detect the ChArUco markers in the photos you captured during the data collection step. The following [tutorial]((https://docs.opencv.org/3.4/da/d13/tutorial_aruco_calibration.html)) may be helpful.\n",
    "\n",
    "### Steps:\n",
    "1. Detect markers: Use the `cv2.aruco.detectMarkers()` function to locate the ArUco markers in each image.\n",
    "2. Calibrate the Camera: Use the `cv2.aruco.calibrateCameraCharuco()` function to calculate the intrinsic camera parameters. Provide the detected ChArUco corners, corresponding IDs, board configuration, and image dimensions. You may find the following [tutorial](https://docs.opencv.org/3.4/da/d13/tutorial_aruco_calibration.html) helpful.\n",
    "3. Output the Intrinsic Parameters: Print the ***camera matrix*** and ***distortion coefficients*** after the calibration process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "gnUrXKXQX3im"
   },
   "outputs": [],
   "source": [
    "aruco_dict = cv2.aruco.Dictionary_get(cv2.aruco.DICT_6X6_50)\n",
    "aruco_params = cv2.aruco.DetectorParameters_create()\n",
    "(corners, ids, rejected) = cv2.aruco.detectMarkers(image, a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fqTgMdOGZU-n"
   },
   "source": [
    "## Pose Estimation (10 pts)\n",
    "\n",
    "Once you have obtained the camera parameters, use them to calculate the pose of the Charuco board. To validate your code, render the axes on 3 of your Charuco board images. You can refer to the following [tutorial](https://docs.opencv.org/3.4/df/d4a/tutorial_charuco_detection.html) for guidance on pose estimation and rendering the axes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9q0t2na3a8JZ"
   },
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w4XvdbWSWw9x"
   },
   "source": [
    "## Observation (5 pts)\n",
    "Write down your observations regarding the results you obtained throughout the `Calibration` section."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NxoBM-RcWw9x"
   },
   "source": [
    "## **TODO: write down your observations**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xNrlXTeKbkUf"
   },
   "source": [
    "# Homography (35 pts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FcVMJdIfcDoh"
   },
   "source": [
    "## Data Preparation\n",
    "\n",
    "Please download the `data.zip` file from the [link](https://drive.google.com/file/d/1Q3NyoeDbKwnp6JeV91gxJkE6m_sMWRmV/view?usp=sharing), and extract it to a location of your choice. For this part of the assignment, use the images in the `homography` folder. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wqVYz91Cdsf6"
   },
   "source": [
    "## Feature Detection (10 pts)\n",
    "\n",
    "After you have the two photos, load them using `cv.imread()`. Convert them to grayscale images. Create a SURF feature detector and detect keypoints on all images. Display the keypoints with size and orientation. For image display (only), adjust the Hessian threshold to show fewer than 30 features.\n",
    "\n",
    "You can follow the tutorial [here](https://docs.opencv.org/4.8.0/df/dd2/tutorial_py_surf_intro.html) to understand the implementation and use of SURF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TCXxIvuZgClz"
   },
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2-rCkw4TgIOE"
   },
   "source": [
    "## Feature Matching (10 pts)\n",
    "\n",
    "Create a FLANN based matcher. Find matches among the descriptors you just detected between every pairs of src-dst images. Graphically show the top-20 matches found by the matcher (for each src-dst pair). You can follow the tutorial in https://docs.opencv.org/4.5.2/dc/dc3/tutorial_py_matcher.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6CKOVvDhhQGC"
   },
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fOCKkk1zjCAd"
   },
   "source": [
    "## Compute Homography (10 pts)\n",
    "\n",
    "Compute the homography using RANSAC. Print out the homography matrix. Transform the four corners of the source image using the homography and display the transformed rectangle on the destination image. You can follow the tutorial in https://docs.opencv.org/4.5.2/d1/de0/tutorial_py_feature_homography.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6Bz5XpSFwFi9"
   },
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kpLHzi5MWGaj"
   },
   "source": [
    "## Observation (5 pts)\n",
    "Write down your observations regarding the results you obtained throughout the `Homography` section."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DaWOQju9WhXA"
   },
   "source": [
    "## **TODO: write down your observations**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T_W6pEH7wi0o"
   },
   "source": [
    "# Panorama (30 pts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ge2sOv3ywzt8"
   },
   "source": [
    "## Data Preparation\n",
    "\n",
    "Please download the `data.zip` file from the [link](https://drive.google.com/file/d/1Q3NyoeDbKwnp6JeV91gxJkE6m_sMWRmV/view?usp=sharing), and extract it to a location of your choice. For this part of the assignment, use the images in the `panorama` folder. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rOLpNVEXxhJq"
   },
   "source": [
    "## Compute Homography (10 pts)\n",
    "Here we are computing homography again, but once every two consecutive images. To do this, you need to first import the images. Then you pick a feature detector (not necessarily SIFT) and detect features. Then you pick a feature matcher (not necessarily brute-force) and find matches between every two consecutive images. Then you compute homography and store them. Below we write a skeleton for you, but you needn't follow it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aHDMzO05yuBE"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2 as cv\n",
    "import os\n",
    "\n",
    "\n",
    "# read images\n",
    "input_path = 'data/panorama/'\n",
    "filenames = [input_path + filename for filename in os.listdir(input_path)]\n",
    "images = [cv.imread(filename) for filename in filenames]\n",
    "count = len(images)\n",
    "\n",
    "homography_matrices = []\n",
    "for i in range(count-1):\n",
    "    # convert to grayscale images\n",
    "    gray1 = cv.cvtColor(images[i], cv.COLOR_BGR2GRAY)\n",
    "    gray2 = cv.cvtColor(images[i+1], cv.COLOR_BGR2GRAY)\n",
    "\n",
    "    # TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Vk72Lv9Cyw6U"
   },
   "source": [
    "## Stitch Panorama (15 pts)\n",
    "Now we can stitch those images to compose a panorama. You need to select an image as an anchor and transform other images onto this anchor image. The transformation between any image and this anchor image is the composition of a series of homography. You should compute the transformations and map all other images onto the anchor image. You can explore other ways to define an anchor. Then you need to blend these image. A possible way is to just take the maximum of the pixel values, but you are encouraged to explore other blending methods (extra points +2~5 pts). After you obtained your panorama, display it along with some intermediate results including feature matches and transformed images. We attached an example in the folder `panorama_output`. Below we provide the code to compute the size of a rectangle that covers all transformed images, but you needn't follow it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3xP8B061aeOr"
   },
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "\n",
    "# TODO: some processing of the homography matrices\n",
    "\n",
    "min_x = min_y = max_x = max_y = 0.0\n",
    "for i in range(count):\n",
    "    # Get the height and width of the original images\n",
    "    h, w, p = images[i].shape\n",
    "    # Create a list of points to represent the corners of the images\n",
    "    corners = np.array([[0, 0], [w, 0], [w, h], [0, h]], dtype=np.float32)\n",
    "    # Calculate the transformed corners\n",
    "    transformed_corners = cv.perspectiveTransform(corners.reshape(-1, 1, 2), homography_matrices[i])\n",
    "    # Find the minimum and maximum coordinates to determine the output size\n",
    "    min_x = min(transformed_corners[:, 0, 0].min(), min_x)\n",
    "    min_y = min(transformed_corners[:, 0, 1].min(), min_y)\n",
    "    max_x = max(transformed_corners[:, 0, 0].max(), max_x)\n",
    "    max_y = max(transformed_corners[:, 0, 1].max(), max_y)\n",
    "\n",
    "# Calculate the width and height of the stitched image\n",
    "output_width = int(max_x - min_x)\n",
    "output_height = int(max_y - min_y)\n",
    "\n",
    "\n",
    "# TODO: blend the transformed images\n",
    "\n",
    "# TODO: display the panorama along with some intermediate results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iWelnlpRWsnT"
   },
   "source": [
    "## Observation (5 pts)\n",
    "Write down your observations regarding the results you obtained throughout the `Panorama` section."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RL5J3s7Kyu4_"
   },
   "source": [
    "## **TODO: write down your observations**"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
